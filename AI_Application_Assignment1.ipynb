{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwC9q0Ylwf1c"
      },
      "source": [
        "# **1.Install required dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUxeu4W-d7X-",
        "outputId": "c594585a-bbc9-4ae7-e199-fb74075188a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WzLaMaeeEuP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate -q\n",
        "!pip install jiwer -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZssUlsRwpBb"
      },
      "source": [
        "# **2.Prepare and Preprocess the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETZNQhFTeExr",
        "outputId": "cb5aed37-2375-4cd7-f140-906a983a263b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'text'],\n",
              "        num_rows: 833\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"lambdalabs/pokemon-blip-captions\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58RikZU-eEz4"
      },
      "outputs": [],
      "source": [
        "ds = ds[\"train\"].train_test_split(test_size=0.1,seed=42)\n",
        "train_ds = ds[\"train\"]\n",
        "test_ds = ds[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2.1 Dataset Subset of 400 Training Examples**"
      ],
      "metadata": {
        "id": "8Vyi55oprYge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Part2\n",
        "ds = ds[\"train\"].train_test_split(test_size=0.1,seed=42)\n",
        "train_subset_400 = train_ds.select(range(400))\n",
        "test_data = ds[\"test\"]"
      ],
      "metadata": {
        "id": "65FLwWTqr93z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8T6Y3etwzGs"
      },
      "source": [
        "# **2.2 Load The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbBhm9xIeE3k"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "modelName = \"microsoft/git-base\"\n",
        "processor = AutoProcessor.from_pretrained(modelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu8GDBOueE5j"
      },
      "outputs": [],
      "source": [
        "#setting for part1\n",
        "def transforms(example_batch):\n",
        "    images = [x for x in example_batch[\"image\"]]\n",
        "    captions = [x for x in example_batch[\"text\"]]\n",
        "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
        "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
        "    return inputs\n",
        "\n",
        "\n",
        "train_ds.set_transform(transforms)\n",
        "test_ds.set_transform(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting for part2\n",
        "def transforms(example_batch):\n",
        "    images = [x for x in example_batch[\"image\"]]\n",
        "    captions = [x for x in example_batch[\"text\"]]\n",
        "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
        "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
        "    return inputs\n",
        "\n",
        "\n",
        "train_subset_400.set_transform(transforms)\n",
        "test_data.set_transform(transforms)"
      ],
      "metadata": {
        "id": "ESb8t4nfvRhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSJMutE-eE7s"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(modelName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYcdjKm7w36f"
      },
      "source": [
        "# **3.Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV8D5YRVeE94"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "\n",
        "\n",
        "wer = load(\"wer\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predicted = logits.argmax(-1)\n",
        "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
        "    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "    return {\"wer_score\": wer_score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAl8DKCBw973"
      },
      "source": [
        "# **4.Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG_nWJ_JecFW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model_name = modelName.split(\"/\")[1]\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-pokemon\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=6,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir='logs',\n",
        "    remove_unused_columns=False,\n",
        "    logging_steps=50,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Km6gVJtoecHz",
        "outputId": "50a297f5-6dac-4539-fad7-c827828fdb79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [282/282 03:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>8.405700</td>\n",
              "      <td>5.678971</td>\n",
              "      <td>17.436409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.941900</td>\n",
              "      <td>3.517781</td>\n",
              "      <td>6.169576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.191000</td>\n",
              "      <td>2.811973</td>\n",
              "      <td>6.192020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory git-base-pokemon/checkpoint-94 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-188 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-282 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"./modelOriginal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxCGw2RWxC3r"
      },
      "source": [
        "# **5.Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKWKgPfrecLw"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = \"https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzfgDMY1jzWq"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "pixel_values = inputs.pixel_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07qVXwKd08fw"
      },
      "outputs": [],
      "source": [
        "inferenceArgs1 = {\n",
        "    \"temperature\": 1.0,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}\n",
        "\n",
        "inferenceArgs2 = {\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":False,\n",
        "}\n",
        "inferenceArgs3 = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynpB3ZAdjzdY",
        "outputId": "4d2634f4-7bea-45fe-e75c-8ff55b051e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 1:  a cartoon character is sitting down with his hands on his hips\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=1.0, do_sample=True .\n",
        "\n",
        "Generated_IDs1 = model.generate(pixel_values=pixel_values, **inferenceArgs1)\n",
        "generated_caption1 = processor.batch_decode(Generated_IDs1, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 1: \", generated_caption1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aZmdrOpjzhj",
        "outputId": "d60bf973-bacd-4f14-a201-d97709df3009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 2:  a cartoon character with a big smile on his face\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.0, do_sample=False .\n",
        "Generated_IDs2 = model.generate(pixel_values=pixel_values, **inferenceArgs2)\n",
        "generated_caption2 = processor.batch_decode(Generated_IDs2, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 2: \", generated_caption2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QfJKuFWk51V",
        "outputId": "c2f05c47-1540-45b6-e9e7-b0b6bd6a240c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 3:  a drawing of a purple and purple cartoon character\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.7, do_sample=True .\n",
        "Generated_IDs3 = model.generate(pixel_values=pixel_values, **inferenceArgs3)\n",
        "generated_caption3 = processor.batch_decode(Generated_IDs3, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 3: \", generated_caption3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osorb0p16S0p"
      },
      "source": [
        "# **Part 2: Impact of Quantity on ML Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "mYC1ZOyV8BTf",
        "outputId": "69ef31e7-3013-409a-9c79-7f0f52c0cc42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 01:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.058100</td>\n",
              "      <td>1.216900</td>\n",
              "      <td>4.899002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.897400</td>\n",
              "      <td>0.565359</td>\n",
              "      <td>5.908978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.501600</td>\n",
              "      <td>0.418934</td>\n",
              "      <td>5.905237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory git-base-pokemon/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-100 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-150 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ],
      "source": [
        "# Trainer for subset with 400 examples\n",
        "trainer_subset_400 = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_subset_400,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model on subset with 400 examples\n",
        "trainer_subset_400.train()\n",
        "trainer_subset_400.save_model(\"./modelSubset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model2 = AutoModelForCausalLM.from_pretrained(\"./modelSubset\")\n",
        "model2 = model2.to(device)\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "pixel_values = inputs.pixel_values\n",
        "pixel_values = pixel_values.to(device)\n",
        "pixel_values = pixel_values.type(next(model.parameters()).dtype)"
      ],
      "metadata": {
        "id": "_GoWFuQw06kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SBVtyp09O5S"
      },
      "outputs": [],
      "source": [
        "inferenceArgs1Subset = {\n",
        "    \"temperature\": 1.0,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}\n",
        "\n",
        "inferenceArgs2Subset = {\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_length\": 100,\n",
        "\n",
        "}\n",
        "inferenceArgs3Subset = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQabGUrP9O8w",
        "outputId": "756852c3-9598-42b8-d595-20a8a82e8df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 1 For The Subset of 400 Training Examples:  a pink and blue cartoon character flying through the air\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=1.0, do_sample=True .\n",
        "\n",
        "Generated_IDs1Subset = model2.generate(pixel_values=pixel_values, **inferenceArgs1Subset)\n",
        "generated_caption1Subset = processor.batch_decode(Generated_IDs1Subset, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 1 For The Subset of 400 Training Examples: \", generated_caption1Subset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHDDexRO9bEa",
        "outputId": "506bccca-e2eb-454c-c893-3e79b8b90f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 2 For The Subset of 400 Training Examples:  a pink and blue cartoon character with a blue tail\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.0, do_sample=False .\n",
        "Generated_IDs2Subset = model2.generate(pixel_values=pixel_values, **inferenceArgs2Subset)\n",
        "generated_caption2Subset = processor.batch_decode(Generated_IDs2Subset, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 2 For The Subset of 400 Training Examples: \", generated_caption2Subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lsOFJ0u9ehu",
        "outputId": "ef818bdd-6b80-4a05-c292-745e116d9ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 3 For The Subset of 400 Training Examples:  a cartoon character with a big smile on his face\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.7, do_sample=True .\n",
        "Generated_IDs3Subset = model2.generate(pixel_values=pixel_values, **inferenceArgs3Subset)\n",
        "generated_caption3Subset = processor.batch_decode(Generated_IDs3Subset, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 3 For The Subset of 400 Training Examples: \", generated_caption3Subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Zx--65LjDP"
      },
      "source": [
        "#**Part 3: Impact of Quality on ML Models**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part3\n",
        "train_ds = ds[\"train\"]\n",
        "exclude_idx = []\n",
        "exclude_words = [\"pink\", \"blue\", \"dragon\", \"pokemon\"]\n",
        "\n",
        "for index, instance in enumerate(train_ds):\n",
        "    caption = instance[\"text\"]\n",
        "    if any(word in caption for word in exclude_words):\n",
        "        exclude_idx.append(index)\n",
        "\n",
        "print(\"Number of excluded items: {}\".format(len(exclude_idx)))\n",
        "\n",
        "train_ds_excluded = train_ds.select([i for i in range(len(train_ds)) if i not in exclude_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oRsUWrN3Zpi",
        "outputId": "7fc5a065-b15a-4bb1-efe1-3062c71d0483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of excluded items: 286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_excluded.set_transform(transforms)"
      ],
      "metadata": {
        "id": "6QAbJNMF586I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "a_bOBJ-SLrsE",
        "outputId": "e2c14129-7900-43c4-82ef-f91ef81c198b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [147/147 02:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.036115</td>\n",
              "      <td>1.381546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.033795</td>\n",
              "      <td>3.399002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.031338</td>\n",
              "      <td>4.152120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory git-base-pokemon/checkpoint-49 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-98 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory git-base-pokemon/checkpoint-147 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trainer_excluded = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds_excluded,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")\n",
        "trainer_excluded.train()\n",
        "trainer_excluded.save_model(\"./modelExcluded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model3 = AutoModelForCausalLM.from_pretrained(\"./modelExcluded\")\n",
        "model3 = model3.to(device)\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "pixel_values = inputs.pixel_values\n",
        "pixel_values = pixel_values.to(device)\n",
        "pixel_values = pixel_values.type(next(model.parameters()).dtype)"
      ],
      "metadata": {
        "id": "NXkPYY033Fez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6ONYNxNLrt_"
      },
      "outputs": [],
      "source": [
        "inferenceArgs1Excluded = {\n",
        "    \"temperature\": 1.0,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}\n",
        "\n",
        "inferenceArgs2Excluded = {\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_length\": 100,\n",
        "\n",
        "}\n",
        "inferenceArgs3Excluded = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_length\": 100,\n",
        "    \"do_sample\":True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH9pWSLdTtQ2",
        "outputId": "daaa1b67-5c9f-4552-b7f9-17af49dda99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 1 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon :  a drawing of a purple and black cartoon character\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=1.0, do_sample=True .\n",
        "\n",
        "Generated_IDs1Excluded = model3.generate(pixel_values=pixel_values, **inferenceArgs1Excluded)\n",
        "generated_caption1Excluded = processor.batch_decode(Generated_IDs1Excluded, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 1 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon : \", generated_caption1Excluded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEG1FoLRTzbd",
        "outputId": "28c0121e-b3fd-4444-c087-3b462121f9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 2 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon :  a cartoon character with a big smile on his face\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.0, do_sample=False .\n",
        "Generated_IDs2Excluded = model3.generate(pixel_values=pixel_values, **inferenceArgs2Excluded)\n",
        "generated_caption2Excluded = processor.batch_decode(Generated_IDs2Excluded, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 2 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon : \", generated_caption2Excluded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhE6LyF0UKGU",
        "outputId": "5badc57e-aaa8-4a97-d7b2-c5446118cc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption Case 3 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon :  a drawing of a purple and black cartoon character\n"
          ]
        }
      ],
      "source": [
        "#Inference on parameters ; temperature=0.7, do_sampleTrue .\n",
        "Generated_IDs3Excluded = model3.generate(pixel_values=pixel_values, **inferenceArgs3Excluded)\n",
        "generated_caption3Excluded = processor.batch_decode(Generated_IDs3Excluded, skip_special_tokens=True)[0]\n",
        "print(\"Generated Caption Case 3 After Removing Training Examples Containing The Words; Pink, Blue, Dragon, And Pokemon : \", generated_caption3Excluded)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}